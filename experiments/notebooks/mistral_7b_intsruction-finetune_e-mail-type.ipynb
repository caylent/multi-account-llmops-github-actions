{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2412a160-b52b-437a-8fdb-c406cc559358",
   "metadata": {},
   "source": [
    "### Set-up: Training Mistral:\n",
    "\n",
    "#### Instruction-finetuning:\n",
    "instruction-tune huggingface-llm-mistral-7b model for a new task. The Mistral-7B-v0.1 Large Language Model (LLM) is a pretrained generative text model with 7 billion parameters. Mistral-7B-v0.1 outperforms Llama 2 13B on all benchmarks we tested. For details, see its HuggingFace webpage.\n",
    "\n",
    "#### Training data\n",
    "Training data is formatted in JSON lines (.jsonl) format, where each line is a dictionary representing a single data sample. All training data must be in a single folder, however it can be saved in multiple jsonl files. The training folder can also contain a template.json file describing the input and output formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9568d3-83da-41aa-8197-ffb39cbca499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('..')\n",
    "from utils.metrics import Evaluate\n",
    "# from utils.utils import Mistral_7B_V1\n",
    "from prompts.mistral_7b_email_type import prompt_data\n",
    "from utils.s3_helper import read_s3_csv_to_dataframe\n",
    "import re\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "import random\n",
    "from sagemaker import hyperparameters\n",
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "from sagemaker import TrainingJobAnalytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb0095-51aa-462d-9ed6-38a4429cc5b8",
   "metadata": {},
   "source": [
    "### 1. Instruction fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c79fe7-6358-4764-9223-2d96d4b7493b",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Pre-requisites: Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b32e05f-e578-4b3f-8c96-7b67bcd274ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# endpoint annd model data\n",
    "endpoint_name = 'hf-llm-mistral-7b-2024-03-26-20-15-13-644'\n",
    "model = \"Mistral_7B\"\n",
    "model_version = \"2.3.0\"\n",
    "model_id = \"huggingface-llm-mistral-7b\"\n",
    "\n",
    "# s3bucket used\n",
    "bucket_name = 'sagemaker-sigparser-caylent-mlops'\n",
    "\n",
    "# input data\n",
    "s3_file_key = 'data/email-type/input/processed/28-03-2024_train.csv'\n",
    "# s3_file_key = 'data/email-type/input/processed/27-03-2024_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c0208-628b-4015-a77d-26885724e2b5",
   "metadata": {},
   "source": [
    "###  1.1. Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3644a2f5-e4e3-4f89-bb71-24611c4d9076",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8204, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_df = read_s3_csv_to_dataframe(bucket_name, s3_file_key)\n",
    "\n",
    "# Use the below code to read the cleaned data locally\n",
    "# cleaned_train_df = pd.read_csv('../data/test-data/data-March-11/cleaned_test_data.csv')\n",
    "cleaned_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b85a2-d3f5-4faa-8c2e-853114912346",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Configure test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6beb90a2-aa51-41c9-8a2e-782e5fce05b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Email Address                 \\t-ng@nationalgypsum.com\n",
       "Email Address Name                               \\t-ng\n",
       "Email Address Display Name                \\t- NG EMAIL\n",
       "Email Type                                  Non-Person\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the record_count number accordingly for quick test purpose(number should be between)\n",
    "# by default we can use the length of the dataframe itself.\n",
    "record_count = len(cleaned_train_df)\n",
    "# record_count = 5\n",
    "temp_train_data = \"\"\n",
    "temp_train_data = cleaned_train_df.head(record_count).copy()\n",
    "temp_train_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ec74b5-ebaf-4d59-8457-fc25ad139e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8204, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61402e51-073e-4e5b-818c-2331c0f48196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Email Address Name</th>\n",
       "      <th>Email Address Display Name</th>\n",
       "      <th>Email Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\t-ng@nationalgypsum.com</td>\n",
       "      <td>\\t-ng</td>\n",
       "      <td>\\t- NG EMAIL</td>\n",
       "      <td>Non-Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t+12134588429.30119168@resources.lync.com</td>\n",
       "      <td>12134588429</td>\n",
       "      <td>\\t+12134588429 30119168</td>\n",
       "      <td>Non-Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\t+12134588429.61498480@resources.lync.com</td>\n",
       "      <td>12134588430</td>\n",
       "      <td>\\t+12134588429 61498480</td>\n",
       "      <td>Non-Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\t+146238799022001@voicemail.com</td>\n",
       "      <td>146238799022001</td>\n",
       "      <td>146238799022001</td>\n",
       "      <td>Non-Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!badlandsroom@acuitybrands.com</td>\n",
       "      <td>!badlandsroom</td>\n",
       "      <td>!JLS-Badlands Room</td>\n",
       "      <td>Non-Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>s.masters@robparal.com</td>\n",
       "      <td>s.masters</td>\n",
       "      <td>Stanley Masters| Power Markets Corp.</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>martinp@ijohep.net</td>\n",
       "      <td>martinp</td>\n",
       "      <td>Martin Park l CDEEF Conference Group</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>mark@foxwoodtaxsearch.com</td>\n",
       "      <td>mark</td>\n",
       "      <td>Mark Morgan/ Service/ Princeton Finance Ltd.</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>colep@robsonsweb.com</td>\n",
       "      <td>colep</td>\n",
       "      <td>COLE POWERS | Keystone Minig Corp.</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>umkeyes@ikegami.com</td>\n",
       "      <td>umkeyes</td>\n",
       "      <td>Ube Martin Keyes - ExoLum Industries</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8204 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Email Address Email Address Name  \\\n",
       "0                       \\t-ng@nationalgypsum.com              \\t-ng   \n",
       "1     \\t+12134588429.30119168@resources.lync.com        12134588429   \n",
       "2     \\t+12134588429.61498480@resources.lync.com        12134588430   \n",
       "3               \\t+146238799022001@voicemail.com    146238799022001   \n",
       "4                 !badlandsroom@acuitybrands.com      !badlandsroom   \n",
       "...                                          ...                ...   \n",
       "8199                      s.masters@robparal.com          s.masters   \n",
       "8200                          martinp@ijohep.net            martinp   \n",
       "8201                   mark@foxwoodtaxsearch.com               mark   \n",
       "8202                        colep@robsonsweb.com              colep   \n",
       "8203                         umkeyes@ikegami.com            umkeyes   \n",
       "\n",
       "                        Email Address Display Name  Email Type  \n",
       "0                                     \\t- NG EMAIL  Non-Person  \n",
       "1                          \\t+12134588429 30119168  Non-Person  \n",
       "2                          \\t+12134588429 61498480  Non-Person  \n",
       "3                                  146238799022001  Non-Person  \n",
       "4                               !JLS-Badlands Room  Non-Person  \n",
       "...                                            ...         ...  \n",
       "8199          Stanley Masters| Power Markets Corp.      Person  \n",
       "8200          Martin Park l CDEEF Conference Group      Person  \n",
       "8201  Mark Morgan/ Service/ Princeton Finance Ltd.      Person  \n",
       "8202            COLE POWERS | Keystone Minig Corp.      Person  \n",
       "8203          Ube Martin Keyes - ExoLum Industries      Person  \n",
       "\n",
       "[8204 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deca8a8-4f24-4818-92a6-54dead7c06c0",
   "metadata": {},
   "source": [
    "#### Get the prompt and print prompt version to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03872266-8727-41ce-b61f-0750df6f542e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prompt_version: version-6\n"
     ]
    }
   ],
   "source": [
    "system_prompt = prompt_data[\"system_prompt\"]\n",
    "instruction = prompt_data[\"instruction\"]\n",
    "prompt_version = prompt_data[\"prompt_version\"]\n",
    "print(\" prompt_version:\", prompt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087ffda-f056-406a-b22d-442efc809804",
   "metadata": {},
   "source": [
    "#### Prepare the user ask with all the relevant data for the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d548fb5c-8c7f-4e69-b168-2a66315c085e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_context(email_address, email_address_name, email_display_name):\n",
    "    email_address = email_address.strip()\n",
    "    email_address_name = email_address_name.strip()\n",
    "    email_display_name = email_display_name.strip()\n",
    "    context_input_str = f\"\"\"Output:\"\"\"\n",
    "    context_data = f\"\"\"{{\"email_address\":\"{email_address}\", \"email_address_name\":\"{email_address_name}\", \"email_display_name\":\"{email_display_name}\"}}\"\"\"\n",
    "    context = context_input_str.strip() + context_data.strip()\n",
    "    return context\n",
    "\n",
    "\n",
    "context = temp_train_data.apply(lambda x: get_context(x['Email Address'], x['Email Address Name'], x['Email Address Display Name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73112501-6d2f-4ba1-9a82-121b84a382f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output:{\"email_address\":\"-ng@nationalgypsum.com\", \"email_address_name\":\"-ng\", \"email_display_name\":\"- NG EMAIL\"}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08f15d5-9518-4c17-a580-4005c87f59f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(email_address_type):\n",
    "    email_address_type = email_address_type.strip().lower()\n",
    "    # email_address_type = email_address_type.lower()\n",
    "    output = f\"\"\"{{\"email_address_type\":\"{email_address_type}\"}}\"\"\"\n",
    "    return output\n",
    "\n",
    "# output = train.apply(lambda x: get_output(x['First Name'], x['Last Name']), axis=1)\n",
    "output = temp_train_data.apply(lambda x: get_output(x['Email Type']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e469fe7b-64e4-4475-8850-da5c78b23827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"email_address_type\":\"non-person\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae9bde-3229-4bca-988c-cabf59a92f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64607ea9-0918-46e6-b146-cf55500fdfe6",
   "metadata": {},
   "source": [
    "#### Prepare the prompts for all the test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd502aa-ad6f-4c25-99fd-fdd3b617e25e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful and detail-oriented assistan...</td>\n",
       "      <td>Please classify this email address for me. All...</td>\n",
       "      <td>Output:{\"email_address\":\"-ng@nationalgypsum.co...</td>\n",
       "      <td>{\"email_address_type\":\"non-person\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful and detail-oriented assistan...</td>\n",
       "      <td>Please classify this email address for me. All...</td>\n",
       "      <td>Output:{\"email_address\":\"+12134588429.30119168...</td>\n",
       "      <td>{\"email_address_type\":\"non-person\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful and detail-oriented assistan...</td>\n",
       "      <td>Please classify this email address for me. All...</td>\n",
       "      <td>Output:{\"email_address\":\"+12134588429.61498480...</td>\n",
       "      <td>{\"email_address_type\":\"non-person\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful and detail-oriented assistan...</td>\n",
       "      <td>Please classify this email address for me. All...</td>\n",
       "      <td>Output:{\"email_address\":\"+146238799022001@voic...</td>\n",
       "      <td>{\"email_address_type\":\"non-person\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful and detail-oriented assistan...</td>\n",
       "      <td>Please classify this email address for me. All...</td>\n",
       "      <td>Output:{\"email_address\":\"!badlandsroom@acuityb...</td>\n",
       "      <td>{\"email_address_type\":\"non-person\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       system_prompt  \\\n",
       "0  You are a helpful and detail-oriented assistan...   \n",
       "1  You are a helpful and detail-oriented assistan...   \n",
       "2  You are a helpful and detail-oriented assistan...   \n",
       "3  You are a helpful and detail-oriented assistan...   \n",
       "4  You are a helpful and detail-oriented assistan...   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  Please classify this email address for me. All...   \n",
       "1  Please classify this email address for me. All...   \n",
       "2  Please classify this email address for me. All...   \n",
       "3  Please classify this email address for me. All...   \n",
       "4  Please classify this email address for me. All...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Output:{\"email_address\":\"-ng@nationalgypsum.co...   \n",
       "1  Output:{\"email_address\":\"+12134588429.30119168...   \n",
       "2  Output:{\"email_address\":\"+12134588429.61498480...   \n",
       "3  Output:{\"email_address\":\"+146238799022001@voic...   \n",
       "4  Output:{\"email_address\":\"!badlandsroom@acuityb...   \n",
       "\n",
       "                              response  \n",
       "0  {\"email_address_type\":\"non-person\"}  \n",
       "1  {\"email_address_type\":\"non-person\"}  \n",
       "2  {\"email_address_type\":\"non-person\"}  \n",
       "3  {\"email_address_type\":\"non-person\"}  \n",
       "4  {\"email_address_type\":\"non-person\"}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({'system_prompt':system_prompt,\n",
    "                         'instruction':instruction,\n",
    "                          'context': context,\n",
    "                          'response': output\n",
    "                        })\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e5f1e33-a02a-4c42-9ad6-240cd79b90bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = {\n",
    "    \"prompt\": \"{system_prompt}\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{context}\",\n",
    "    \"completion\": \"{response}\",\n",
    "}\n",
    "with open(\"../data/Mistral_7B/template.json\", \"w\") as f:\n",
    "    json.dump(template, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "726c5071-67b8-40c6-9bbe-88475a9bef1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral-7b-fine-tuning-dataset-version-6.jsonl\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_path = f\"../data/Mistral_7B/mistral-7b-fine-tuning-dataset-{prompt_version}.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(train_df.to_json(orient='records', lines=True, force_ascii=False))\n",
    "\n",
    "\n",
    "object_name = f\"data/email-type/input/training/{model}/{timestamp}\"\n",
    "# Create the file name as per the task: name-parse, email-signature\n",
    "file_name = f\"mistral-7b-fine-tuning-dataset-{prompt_version}.jsonl\"\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6ed105-3062-4d9e-a8de-eedb95481f71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://sagemaker-sigparser-caylent-mlops/data/email-type/input/training/Mistral_7B/2024-03-28_23-15-26\n"
     ]
    }
   ],
   "source": [
    "local_data_file = output_path\n",
    "train_data_location = f\"s3://{bucket_name}/{object_name}\"\n",
    "S3Uploader.upload(local_data_file, train_data_location)\n",
    "S3Uploader.upload(\"../data/Mistral_7B/template.json\", train_data_location)\n",
    "print(f\"Training data: {train_data_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f4f7c-cf16-46b7-b59b-5e0db4ed2baf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a8c136f-9281-4c31-915a-d7070c0bb1bf",
   "metadata": {},
   "source": [
    "### 1.2. Prepare training parameters\n",
    "\n",
    "##### Figureout the hyper params for the use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e952774-b75f-4238-aa34-e62a97b98380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'peft_type': 'None', 'instruction_tuned': 'True', 'chat_dataset': 'False', 'epoch': '1', 'learning_rate': '6e-06', 'lora_r': '64', 'lora_alpha': '16', 'lora_dropout': '0', 'bits': '16', 'double_quant': 'True', 'quant_type': 'nf4', 'per_device_train_batch_size': '2', 'per_device_eval_batch_size': '8', 'add_input_output_demarcation_key': 'True', 'warmup_ratio': '0.1', 'train_from_scratch': 'False', 'fp16': 'False', 'bf16': 'True', 'evaluation_strategy': 'steps', 'eval_steps': '20', 'gradient_accumulation_steps': '8', 'logging_steps': '8', 'weight_decay': '0.2', 'load_best_model_at_end': 'True', 'max_train_samples': '-1', 'max_val_samples': '-1', 'seed': '10', 'max_input_length': '-1', 'validation_split_ratio': '0.2', 'train_data_split_seed': '0', 'preprocessing_num_workers': 'None', 'max_steps': '-1', 'gradient_checkpointing': 'True', 'early_stopping_patience': '3', 'early_stopping_threshold': '0.0', 'adam_beta1': '0.9', 'adam_beta2': '0.999', 'adam_epsilon': '1e-08', 'max_grad_norm': '1.0', 'label_smoothing_factor': '0', 'logging_first_step': 'False', 'logging_nan_inf_filter': 'True', 'save_strategy': 'steps', 'save_steps': '500', 'save_total_limit': '1', 'dataloader_drop_last': 'False', 'dataloader_num_workers': '0', 'eval_accumulation_steps': 'None', 'auto_find_batch_size': 'False', 'lr_scheduler_type': 'constant_with_warmup', 'warmup_steps': '0'}\n"
     ]
    }
   ],
   "source": [
    "my_hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=model_id, model_version=model_version\n",
    ")\n",
    "print(my_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91aa4d-b297-4bb8-a854-c0eb8e6b8a4b",
   "metadata": {},
   "source": [
    "##### Overwrite the hyperparameters. Note. You can select the LoRA method for your fine-tuning by selecting peft_type=lora in the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebaade16-167c-475b-861a-8eb077c43fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'peft_type': 'None', 'instruction_tuned': 'True', 'chat_dataset': 'False', 'epoch': '2', 'learning_rate': '6e-06', 'lora_r': '64', 'lora_alpha': '16', 'lora_dropout': '0', 'bits': '16', 'double_quant': 'True', 'quant_type': 'nf4', 'per_device_train_batch_size': '2', 'per_device_eval_batch_size': '8', 'add_input_output_demarcation_key': 'True', 'warmup_ratio': '0.1', 'train_from_scratch': 'False', 'fp16': 'False', 'bf16': 'True', 'evaluation_strategy': 'steps', 'eval_steps': '20', 'gradient_accumulation_steps': '2', 'logging_steps': '8', 'weight_decay': '0.2', 'load_best_model_at_end': 'True', 'max_train_samples': '-1', 'max_val_samples': '-1', 'seed': '10', 'max_input_length': '-1', 'validation_split_ratio': '0.2', 'train_data_split_seed': '0', 'preprocessing_num_workers': 'None', 'max_steps': '-1', 'gradient_checkpointing': 'True', 'early_stopping_patience': '3', 'early_stopping_threshold': '0.0', 'adam_beta1': '0.9', 'adam_beta2': '0.999', 'adam_epsilon': '1e-08', 'max_grad_norm': '1.0', 'label_smoothing_factor': '0', 'logging_first_step': 'False', 'logging_nan_inf_filter': 'True', 'save_strategy': 'steps', 'save_steps': '500', 'save_total_limit': '1', 'dataloader_drop_last': 'False', 'dataloader_num_workers': '0', 'eval_accumulation_steps': 'None', 'auto_find_batch_size': 'False', 'lr_scheduler_type': 'constant_with_warmup', 'warmup_steps': '0'}\n"
     ]
    }
   ],
   "source": [
    "my_hyperparameters[\"epoch\"] = \"2\"\n",
    "my_hyperparameters[\"per_device_train_batch_size\"] = \"2\"\n",
    "my_hyperparameters[\"gradient_accumulation_steps\"] = \"2\"\n",
    "my_hyperparameters[\"instruction_tuned\"] = \"True\"\n",
    "print(my_hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501b90d-fb22-4e4c-9ea0-8e17f5e89ed6",
   "metadata": {},
   "source": [
    "##### Validate hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b4a8641-4135-4c7a-9a8d-a3f1a2ef8f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters.validate(\n",
    "    model_id=model_id, model_version=model_version, hyperparameters=my_hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec74b00-bacf-4905-a4e2-77836f704ef6",
   "metadata": {},
   "source": [
    "## Under Implementation. Run the below cells only after creating the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deae7da-e50d-4b4c-b49c-4f68b1916a75",
   "metadata": {},
   "source": [
    "### 1.3. Starting training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2cf1b-9a4a-480c-ba6b-fb82f0f54c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: hf-llm-mistral-7b-2024-03-28-23-21-00-628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-28 23:21:01 Starting - Starting the training job...\n",
      "2024-03-28 23:21:28 Pending - Training job waiting for capacity...\n",
      "2024-03-28 23:21:54 Pending - Preparing the instances for training......\n",
      "2024-03-28 23:22:51 Downloading - Downloading input data.......................................\n",
      "2024-03-28 23:29:32 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-28 23:29:34,319 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-28 23:29:34,373 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-28 23:29:34,383 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-28 23:29:34,385 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-28 23:29:36,771 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./lib/accelerate/accelerate-0.26.1-py3-none-any.whl (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/bitsandbytes/bitsandbytes-0.42.0-py3-none-any.whl (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/deepspeed/deepspeed-0.10.3.tar.gz\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mProcessing ./lib/docstring-parser/docstring_parser-0.15-py3-none-any.whl (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/flash_attn/flash_attn-2.5.5-cp310-cp310-linux_x86_64.whl (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/ninja/ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/packaging/packaging-23.2-py3-none-any.whl (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/peft/peft-0.8.2-py3-none-any.whl (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/py_cpuinfo/py_cpuinfo-9.0.0-py3-none-any.whl (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/rich/rich-13.7.0-py3-none-any.whl (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/safetensors/safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from -r requirements.txt (line 11))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/shtab/shtab-1.6.5-py3-none-any.whl (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tokenizers/tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from -r requirements.txt (line 13))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/transformers/transformers-4.38.1-py3-none-any.whl (from -r requirements.txt (line 14))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/trl/trl-0.7.10-py3-none-any.whl (from -r requirements.txt (line 15))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/tyro/tyro-0.7.2-py3-none-any.whl (from -r requirements.txt (line 16))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_tabular_script_utilities/sagemaker_jumpstart_tabular_script_utilities-1.0.0-py2.py3-none-any.whl (from -r requirements.txt (line 17))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_huggingface_script_utilities/sagemaker_jumpstart_huggingface_script_utilities-1.2.2-py2.py3-none-any.whl (from -r requirements.txt (line 18))\u001b[0m\n",
      "\u001b[34mProcessing ./lib/sagemaker_jumpstart_script_utilities/sagemaker_jumpstart_script_utilities-1.1.10-py2.py3-none-any.whl (from -r requirements.txt (line 19))\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 2)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (1.10.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.5->-r requirements.txt (line 5)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.7.0->-r requirements.txt (line 10)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.7.0->-r requirements.txt (line 10)) (2.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.10->-r requirements.txt (line 15)) (2.16.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from tyro==0.7.2->-r requirements.txt (line 16)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.26.1->-r requirements.txt (line 1)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 10)) (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (14.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.16.0)\u001b[0m\n",
      "\u001b[34mninja is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\u001b[0m\n",
      "\u001b[34mpy-cpuinfo is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: deepspeed\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for deepspeed (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for deepspeed: filename=deepspeed-0.10.3-py3-none-any.whl size=907839 sha256=277fa509ba1c2ae353562c8b5a64d0a038f55bcda1cba8bf90e5e7dbb3dce586\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/b4/a0/a9/4723ccba9b5790d90f40617f369a69c6dff729fa4b0aa6e131\u001b[0m\n",
      "\u001b[34mSuccessfully built deepspeed\u001b[0m\n",
      "\u001b[34mInstalling collected packages: shtab, sagemaker-jumpstart-tabular-script-utilities, sagemaker-jumpstart-script-utilities, sagemaker-jumpstart-huggingface-script-utilities, safetensors, packaging, docstring-parser, rich, bitsandbytes, tyro, tokenizers, flash-attn, deepspeed, accelerate, transformers, trl, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: packaging\u001b[0m\n",
      "\u001b[34mFound existing installation: packaging 23.1\u001b[0m\n",
      "\u001b[34mUninstalling packaging-23.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled packaging-23.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: rich\u001b[0m\n",
      "\u001b[34mFound existing installation: rich 13.4.2\u001b[0m\n",
      "\u001b[34mUninstalling rich-13.4.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled rich-13.4.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mAttempting uninstall: deepspeed\u001b[0m\n",
      "\u001b[34mFound existing installation: deepspeed 0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mUninstalling deepspeed-0.6.1+1ea3d4b:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled deepspeed-0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.26.1 bitsandbytes-0.42.0 deepspeed-0.10.3 docstring-parser-0.15 flash-attn-2.5.5 packaging-23.2 peft-0.8.2 rich-13.7.0 safetensors-0.4.2 sagemaker-jumpstart-huggingface-script-utilities-1.2.2 sagemaker-jumpstart-script-utilities-1.1.10 sagemaker-jumpstart-tabular-script-utilities-1.0.0 shtab-1.6.5 tokenizers-0.15.1 transformers-4.38.1 trl-0.7.10 tyro-0.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:04,911 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:04,911 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:05,029 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:05,122 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:05,214 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:05,223 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"code\": \"/opt/ml/input/data/code\",\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.24xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam_beta1\": \"0.9\",\n",
      "        \"adam_beta2\": \"0.999\",\n",
      "        \"adam_epsilon\": \"1e-08\",\n",
      "        \"add_input_output_demarcation_key\": \"True\",\n",
      "        \"auto_find_batch_size\": \"False\",\n",
      "        \"bf16\": \"True\",\n",
      "        \"bits\": \"16\",\n",
      "        \"chat_dataset\": \"False\",\n",
      "        \"dataloader_drop_last\": \"False\",\n",
      "        \"dataloader_num_workers\": \"0\",\n",
      "        \"double_quant\": \"True\",\n",
      "        \"early_stopping_patience\": \"3\",\n",
      "        \"early_stopping_threshold\": \"0.0\",\n",
      "        \"epoch\": \"2\",\n",
      "        \"eval_accumulation_steps\": \"None\",\n",
      "        \"eval_steps\": \"20\",\n",
      "        \"evaluation_strategy\": \"steps\",\n",
      "        \"fp16\": \"False\",\n",
      "        \"gradient_accumulation_steps\": \"2\",\n",
      "        \"gradient_checkpointing\": \"True\",\n",
      "        \"instruction_tuned\": \"True\",\n",
      "        \"label_smoothing_factor\": \"0\",\n",
      "        \"learning_rate\": \"6e-06\",\n",
      "        \"load_best_model_at_end\": \"True\",\n",
      "        \"logging_first_step\": \"False\",\n",
      "        \"logging_nan_inf_filter\": \"True\",\n",
      "        \"logging_steps\": \"8\",\n",
      "        \"lora_alpha\": \"16\",\n",
      "        \"lora_dropout\": \"0\",\n",
      "        \"lora_r\": \"64\",\n",
      "        \"lr_scheduler_type\": \"constant_with_warmup\",\n",
      "        \"max_grad_norm\": \"1.0\",\n",
      "        \"max_input_length\": \"-1\",\n",
      "        \"max_steps\": \"-1\",\n",
      "        \"max_train_samples\": \"-1\",\n",
      "        \"max_val_samples\": \"-1\",\n",
      "        \"peft_type\": \"None\",\n",
      "        \"per_device_eval_batch_size\": \"8\",\n",
      "        \"per_device_train_batch_size\": \"2\",\n",
      "        \"preprocessing_num_workers\": \"None\",\n",
      "        \"quant_type\": \"nf4\",\n",
      "        \"save_steps\": \"500\",\n",
      "        \"save_strategy\": \"steps\",\n",
      "        \"save_total_limit\": \"1\",\n",
      "        \"seed\": \"10\",\n",
      "        \"train_data_split_seed\": \"0\",\n",
      "        \"train_from_scratch\": \"False\",\n",
      "        \"validation_split_ratio\": \"0.2\",\n",
      "        \"warmup_ratio\": \"0.1\",\n",
      "        \"warmup_steps\": \"0\",\n",
      "        \"weight_decay\": \"0.2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"code\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"hf-llm-mistral-7b-2024-03-28-23-21-00-628\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/input/data/code/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"add_input_output_demarcation_key\":\"True\",\"auto_find_batch_size\":\"False\",\"bf16\":\"True\",\"bits\":\"16\",\"chat_dataset\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"double_quant\":\"True\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"2\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"False\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":\"True\",\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"8\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0\",\"lora_r\":\"64\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"-1\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"peft_type\":\"None\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"2\",\"preprocessing_num_workers\":\"None\",\"quant_type\":\"nf4\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"code\",\"model\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/input/data/code/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"code\":\"/opt/ml/input/data/code\",\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.24xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"add_input_output_demarcation_key\":\"True\",\"auto_find_batch_size\":\"False\",\"bf16\":\"True\",\"bits\":\"16\",\"chat_dataset\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"double_quant\":\"True\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"2\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"False\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":\"True\",\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"8\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0\",\"lora_r\":\"64\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"-1\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"peft_type\":\"None\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"2\",\"preprocessing_num_workers\":\"None\",\"quant_type\":\"nf4\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"hf-llm-mistral-7b-2024-03-28-23-21-00-628\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/input/data/code/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam_beta1\",\"0.9\",\"--adam_beta2\",\"0.999\",\"--adam_epsilon\",\"1e-08\",\"--add_input_output_demarcation_key\",\"True\",\"--auto_find_batch_size\",\"False\",\"--bf16\",\"True\",\"--bits\",\"16\",\"--chat_dataset\",\"False\",\"--dataloader_drop_last\",\"False\",\"--dataloader_num_workers\",\"0\",\"--double_quant\",\"True\",\"--early_stopping_patience\",\"3\",\"--early_stopping_threshold\",\"0.0\",\"--epoch\",\"2\",\"--eval_accumulation_steps\",\"None\",\"--eval_steps\",\"20\",\"--evaluation_strategy\",\"steps\",\"--fp16\",\"False\",\"--gradient_accumulation_steps\",\"2\",\"--gradient_checkpointing\",\"True\",\"--instruction_tuned\",\"True\",\"--label_smoothing_factor\",\"0\",\"--learning_rate\",\"6e-06\",\"--load_best_model_at_end\",\"True\",\"--logging_first_step\",\"False\",\"--logging_nan_inf_filter\",\"True\",\"--logging_steps\",\"8\",\"--lora_alpha\",\"16\",\"--lora_dropout\",\"0\",\"--lora_r\",\"64\",\"--lr_scheduler_type\",\"constant_with_warmup\",\"--max_grad_norm\",\"1.0\",\"--max_input_length\",\"-1\",\"--max_steps\",\"-1\",\"--max_train_samples\",\"-1\",\"--max_val_samples\",\"-1\",\"--peft_type\",\"None\",\"--per_device_eval_batch_size\",\"8\",\"--per_device_train_batch_size\",\"2\",\"--preprocessing_num_workers\",\"None\",\"--quant_type\",\"nf4\",\"--save_steps\",\"500\",\"--save_strategy\",\"steps\",\"--save_total_limit\",\"1\",\"--seed\",\"10\",\"--train_data_split_seed\",\"0\",\"--train_from_scratch\",\"False\",\"--validation_split_ratio\",\"0.2\",\"--warmup_ratio\",\"0.1\",\"--warmup_steps\",\"0\",\"--weight_decay\",\"0.2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CODE=/opt/ml/input/data/code\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_BETA2=0.999\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM_EPSILON=1e-08\u001b[0m\n",
      "\u001b[34mSM_HP_ADD_INPUT_OUTPUT_DEMARCATION_KEY=True\u001b[0m\n",
      "\u001b[34mSM_HP_AUTO_FIND_BATCH_SIZE=False\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=True\u001b[0m\n",
      "\u001b[34mSM_HP_BITS=16\u001b[0m\n",
      "\u001b[34mSM_HP_CHAT_DATASET=False\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_DROP_LAST=False\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_NUM_WORKERS=0\u001b[0m\n",
      "\u001b[34mSM_HP_DOUBLE_QUANT=True\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=3\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_THRESHOLD=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=2\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_ACCUMULATION_STEPS=None\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_STEPS=20\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_STRATEGY=steps\u001b[0m\n",
      "\u001b[34mSM_HP_FP16=False\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=True\u001b[0m\n",
      "\u001b[34mSM_HP_INSTRUCTION_TUNED=True\u001b[0m\n",
      "\u001b[34mSM_HP_LABEL_SMOOTHING_FACTOR=0\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=6e-06\u001b[0m\n",
      "\u001b[34mSM_HP_LOAD_BEST_MODEL_AT_END=True\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_FIRST_STEP=False\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_NAN_INF_FILTER=True\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=8\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_ALPHA=16\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_DROPOUT=0\u001b[0m\n",
      "\u001b[34mSM_HP_LORA_R=64\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=constant_with_warmup\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_INPUT_LENGTH=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_STEPS=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_TRAIN_SAMPLES=-1\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_VAL_SAMPLES=-1\u001b[0m\n",
      "\u001b[34mSM_HP_PEFT_TYPE=None\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_PREPROCESSING_NUM_WORKERS=None\u001b[0m\n",
      "\u001b[34mSM_HP_QUANT_TYPE=nf4\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STEPS=500\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=steps\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=1\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=10\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_DATA_SPLIT_SEED=0\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FROM_SCRATCH=False\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_SPLIT_RATIO=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=0\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 transfer_learning.py --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-08 --add_input_output_demarcation_key True --auto_find_batch_size False --bf16 True --bits 16 --chat_dataset False --dataloader_drop_last False --dataloader_num_workers 0 --double_quant True --early_stopping_patience 3 --early_stopping_threshold 0.0 --epoch 2 --eval_accumulation_steps None --eval_steps 20 --evaluation_strategy steps --fp16 False --gradient_accumulation_steps 2 --gradient_checkpointing True --instruction_tuned True --label_smoothing_factor 0 --learning_rate 6e-06 --load_best_model_at_end True --logging_first_step False --logging_nan_inf_filter True --logging_steps 8 --lora_alpha 16 --lora_dropout 0 --lora_r 64 --lr_scheduler_type constant_with_warmup --max_grad_norm 1.0 --max_input_length -1 --max_steps -1 --max_train_samples -1 --max_val_samples -1 --peft_type None --per_device_eval_batch_size 8 --per_device_train_batch_size 2 --preprocessing_num_workers None --quant_type nf4 --save_steps 500 --save_strategy steps --save_total_limit 1 --seed 10 --train_data_split_seed 0 --train_from_scratch False --validation_split_ratio 0.2 --warmup_ratio 0.1 --warmup_steps 0 --weight_decay 0.2\u001b[0m\n",
      "\u001b[34m2024-03-28 23:30:05,253 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mFound existing installation: diffusers 0.16.1\u001b[0m\n",
      "\u001b[34mUninstalling diffusers-0.16.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled diffusers-0.16.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:30:08,789] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mINFO:root:Running training scripts with arguments: Namespace(model_dir='/opt/ml/model', train=None, train_alt='/opt/ml/input/data/train', validation=None, hosts=['algo-1'], num_gpus=4, current_host='algo-1', pretrained_model='/opt/ml/input/data/model', peft_type='None', lora_r=64, lora_alpha=16, lora_dropout=0.0, bits=16, double_quant=True, quant_type='nf4', deepspeed=True, instruction_tuned='True', chat_dataset='False', train_from_scratch='False', fp16='False', bf16='True', evaluation_strategy='steps', eval_steps=20, epoch=2, gradient_accumulation_steps=2, per_device_train_batch_size=2, per_device_eval_batch_size=8, logging_steps=8, warmup_ratio=0.1, learning_rate=6e-06, weight_decay=0.2, load_best_model_at_end='True', max_train_samples=-1, max_val_samples=-1, seed=10, max_input_length=-1, validation_split_ratio=0.2, train_data_split_seed=0, preprocessing_num_workers=None, max_steps=-1, gradient_checkpointing='True', early_stopping_patience=3, early_stopping_threshold=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, label_smoothing_factor=0.0, logging_strategy='steps', logging_first_step='False', logging_nan_inf_filter='True', save_strategy='steps', save_steps=500, save_total_limit=1, dataloader_drop_last='False', dataloader_num_workers=0, eval_accumulation_steps=None, auto_find_batch_size='False', lr_scheduler_type='constant_with_warmup', warmup_steps=0, add_input_output_demarcation_key='True').\u001b[0m\n",
      "\u001b[34mINFO:root:Ignoring unrecognized arguments: [].\u001b[0m\n",
      "\u001b[34mINFO:root:Uncompressing the input model tarball.\u001b[0m\n",
      "\u001b[34mINFO:root:Parameter 'instruction_tuned' is 'True'. Starting instruction fine-tuning.\u001b[0m\n",
      "\u001b[34mINFO:root:Running command ['deepspeed', '--num_gpus=4', '/opt/conda/lib/python3.10/site-packages/sagemaker_jumpstart_huggingface_script_utilities/fine_tuning/run_clm.py', '--deepspeed', 'ds_config.json', '--model_name_or_path', '/tmp', '--train_file', '/opt/ml/input/data/train', '--do_train', '--output_dir', '/opt/ml/model', '--num_train_epochs', '2', '--gradient_accumulation_steps', '2', '--per_device_train_batch_size', '2', '--per_device_eval_batch_size', '8', '--logging_steps', '8', '--warmup_ratio', '0.1', '--learning_rate', '6e-06', '--weight_decay', '0.2', '--seed', '10', '--max_input_length', '-1', '--validation_split_ratio', '0.2', '--train_data_split_seed', '0', '--max_steps', '-1', '--early_stopping_patience', '3', '--early_stopping_threshold', '0.0', '--adam_beta1', '0.9', '--adam_beta2', '0.999', '--max_grad_norm', '1.0', '--label_smoothing_factor', '0.0', '--logging_strategy', 'steps', '--save_strategy', 'steps', '--save_steps', '500', '--dataloader_num_workers', '0', '--lr_scheduler_type', 'constant_with_warmup', '--warmup_steps', '0', '--evaluation_strategy', 'steps', '--eval_steps', '20', '--lora_r', '64', '--lora_alpha', '16', '--lora_dropout', '0.0', '--bits', '16', '--quant_type', 'nf4', '--add_input_output_demarcation_key', 'True', '--load_best_model_at_end', '--bf16', '--instruction_tuned', '--gradient_checkpointing', '--save_total_limit', '1', '--double_quant']\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:02,069] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:04,760] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:04,760] [INFO] [runner.py:570:main] cmd = /opt/conda/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /opt/conda/lib/python3.10/site-packages/sagemaker_jumpstart_huggingface_script_utilities/fine_tuning/run_clm.py --deepspeed ds_config.json --model_name_or_path /tmp --train_file /opt/ml/input/data/train --do_train --output_dir /opt/ml/model --num_train_epochs 2 --gradient_accumulation_steps 2 --per_device_train_batch_size 2 --per_device_eval_batch_size 8 --logging_steps 8 --warmup_ratio 0.1 --learning_rate 6e-06 --weight_decay 0.2 --seed 10 --max_input_length -1 --validation_split_ratio 0.2 --train_data_split_seed 0 --max_steps -1 --early_stopping_patience 3 --early_stopping_threshold 0.0 --adam_beta1 0.9 --adam_beta2 0.999 --max_grad_norm 1.0 --label_smoothing_factor 0.0 --logging_strategy steps --save_strategy steps --save_steps 500 --dataloader_num_workers 0 --lr_scheduler_type constant_with_warmup --warmup_steps 0 --evaluation_strategy steps --eval_steps 20 --lora_r 64 --lora_alpha 16 --lora_dropout 0.0 --bits 16 --quant_type nf4 --add_input_output_demarcation_key True --load_best_model_at_end --bf16 --instruction_tuned --gradient_checkpointing --save_total_limit 1 --double_quant\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:06,350] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:138:main] 0 NCCL_DEBUG=WARN\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:138:main] 0 NCCL_SOCKET_IFNAME=eth0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:138:main] 0 NCCL_IB_DISABLE=1\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.16.2\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:163:main] dist_world_size=4\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:09,000] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:15,202] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:15,210] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:15,220] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:15,224] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:18,460] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:18,499] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:18,501] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:18,501] [INFO] [comm.py:637:init_distributed] cdb=None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:18,501] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - WARNING - jumpstart -   Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - WARNING - jumpstart -   Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - WARNING - jumpstart -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - WARNING - jumpstart -   Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - INFO - jumpstart -   Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34maccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=True,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_persistent_workers=False,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mdataloader_prefetch_factor=None,\u001b[0m\n",
      "\u001b[34mddp_backend=None,\u001b[0m\n",
      "\u001b[34mddp_broadcast_buffers=None,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=ds_config.json,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdispatch_batches=None,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=20,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=steps,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=2,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=True,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing_kwargs=None,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_always_push=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34minclude_num_input_tokens_seen=False,\u001b[0m\n",
      "\u001b[34minclude_tokens_per_second=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=6e-06,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=warning,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/runs/Mar28_23-32-18_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=8,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_kwargs={},\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=constant_with_warmup,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mneftune_noise_alpha=None,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=2.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_torch,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=2,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=['tensorboard'],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_only_model=False,\u001b[0m\n",
      "\u001b[34msave_safetensors=True,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=steps,\u001b[0m\n",
      "\u001b[34msave_total_limit=1,\u001b[0m\n",
      "\u001b[34mseed=10,\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34msplit_batches=None,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_cpu=False,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.1,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.2,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer.model\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer.model\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file added_tokens.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2044] 2024-03-28 23:32:19,700 >> loading file tokenizer_config.json\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:726] 2024-03-28 23:32:19,753 >> loading configuration file /tmp/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:726] 2024-03-28 23:32:19,753 >> loading configuration file /tmp/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:791] 2024-03-28 23:32:19,754 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:791] 2024-03-28 23:32:19,754 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:19 - INFO - jumpstart -   Overwrite use_cache to be False in the model config.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3254] 2024-03-28 23:32:19,792 >> loading weights file /tmp/pytorch_model.bin.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3254] 2024-03-28 23:32:19,792 >> loading weights file /tmp/pytorch_model.bin.index.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1400] 2024-03-28 23:32:19,792 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1400] 2024-03-28 23:32:19,792 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3363] 2024-03-28 23:32:19,792 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3363] 2024-03-28 23:32:19,792 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34mYou are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:329] 2024-03-28 23:32:19,798 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34m[WARNING|logging.py:329] 2024-03-28 23:32:19,798 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:845] 2024-03-28 23:32:19,808 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:845] 2024-03-28 23:32:19,808 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mNCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:26,180] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 7.24B\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.04s/it]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.04s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.04s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.52s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.70s/it]#015Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.70s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.20s/it]\u001b[0m\n",
      "\u001b[34m#015Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.20s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.70s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.20s/it]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 8204 examples [00:00, 173291.99 examples/s]\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - WARNING - jumpstart -   The tokenizer picked has a `model_max_length` (1000000000000000019884624838656) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - WARNING - jumpstart -   The tokenizer picked has a `model_max_length` (1000000000000000019884624838656) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - WARNING - jumpstart -   The tokenizer picked has a `model_max_length` (1000000000000000019884624838656) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template: 100%|██████████| 8204/8204 [00:00<00:00, 87027.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template: 100%|██████████| 8204/8204 [00:00<00:00, 85496.80 examples/s]\u001b[0m\n",
      "\u001b[34mGenerate examples in the format of prompt template: 100%|██████████| 8204/8204 [00:00<00:00, 86112.58 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.74s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.31s/it]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3992] 2024-03-28 23:32:42,838 >> All model checkpoint weights were used when initializing MistralForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:3992] 2024-03-28 23:32:42,838 >> All model checkpoint weights were used when initializing MistralForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4000] 2024-03-28 23:32:42,838 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /tmp.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:4000] 2024-03-28 23:32:42,838 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /tmp.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:798] 2024-03-28 23:32:42,843 >> loading configuration file /tmp/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:798] 2024-03-28 23:32:42,843 >> loading configuration file /tmp/generation_config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:845] 2024-03-28 23:32:42,843 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:845] 2024-03-28 23:32:42,843 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - INFO - jumpstart -   Training data is identified. The corresponded column names are ['system_prompt', 'instruction', 'context', 'response'].\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - WARNING - jumpstart -   The tokenizer picked has a `model_max_length` (1000000000000000019884624838656) larger than maximum input length cap 1024. Picking 1024 instead.\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:42 - INFO - jumpstart -   The max sequence length is set as 1024.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/8204 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 1000/8204 [00:00<00:01, 4465.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 1000/8204 [00:00<00:01, 4226.06 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 1000/8204 [00:00<00:01, 4480.50 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 2000/8204 [00:00<00:01, 5173.46 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 2000/8204 [00:00<00:01, 4996.33 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 2000/8204 [00:00<00:01, 5171.25 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 1000/8204 [00:00<00:03, 2112.97 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 3000/8204 [00:00<00:00, 5478.16 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 3000/8204 [00:00<00:00, 5513.55 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 3000/8204 [00:00<00:00, 5512.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 2000/8204 [00:00<00:01, 3410.98 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 4000/8204 [00:00<00:00, 5702.88 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 4000/8204 [00:00<00:00, 5696.10 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 4000/8204 [00:00<00:00, 5759.45 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 3000/8204 [00:00<00:01, 4267.86 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 5000/8204 [00:00<00:00, 5769.60 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 5000/8204 [00:00<00:00, 5761.87 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 4000/8204 [00:00<00:00, 4890.92 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 5000/8204 [00:00<00:00, 5779.03 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 6000/8204 [00:01<00:00, 5874.32 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 6000/8204 [00:01<00:00, 5835.29 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 5000/8204 [00:01<00:00, 5207.28 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 6000/8204 [00:01<00:00, 5778.30 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 7000/8204 [00:01<00:00, 5914.01 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 7000/8204 [00:01<00:00, 5890.37 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 7000/8204 [00:01<00:00, 5807.38 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 6000/8204 [00:01<00:00, 4935.90 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 8000/8204 [00:01<00:00, 5969.79 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 8000/8204 [00:01<00:00, 5933.68 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 8204/8204 [00:01<00:00, 5698.04 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 8204/8204 [00:01<00:00, 5690.73 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 8000/8204 [00:01<00:00, 5888.57 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▌ | 7000/8204 [00:01<00:00, 5392.70 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 8204/8204 [00:01<00:00, 5679.76 examples/s]\u001b[0m\n",
      "\u001b[34m03/28/2024 23:32:44 - INFO - jumpstart -   Test data is not identified. Split the data into train and test data respectively.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1875] 2024-03-28 23:32:44,354 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32004. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1875] 2024-03-28 23:32:44,354 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32004. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 8000/8204 [00:01<00:00, 5747.44 examples/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 8204/8204 [00:01<00:00, 4842.78 examples/s]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:601] 2024-03-28 23:32:44,991 >> Using auto half precision backend\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:601] 2024-03-28 23:32:44,991 >> Using auto half precision backend\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:45,116] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:32:45,136] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py310_cu118/cpu_adam...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mDetected CUDA files, patching ldflags\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34m[1/4] /opt/conda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o\u001b[0m\n",
      "\u001b[34m[2/4] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o\u001b[0m\n",
      "\u001b[34m[3/4] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o\u001b[0m\n",
      "\u001b[34m[4/4] c++ cpu_adam.o cpu_adam_impl.o custom_cuda_kernel.cuda.o -shared -lcurand -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/conda/lib64 -lcudart -o cpu_adam.so\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 30.01624083518982 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 30.106876850128174 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 30.114754676818848 seconds\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 30.11505103111267 seconds\u001b[0m\n",
      "\u001b[34mAdam Optimizer #0 is created with AVX2 arithmetic capability.\u001b[0m\n",
      "\u001b[34mConfig: alpha=0.000006, betas=(0.900000, 0.999000), weight_decay=0.200000, adam_w=1\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,341] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,358] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,358] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,358] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,358] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,476] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,476] [INFO] [utils.py:804:see_memory_usage] MA 0.99 GB         Max_MA 1.48 GB         CA 1.07 GB         Max_CA 2 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,477] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 48.8 GB, percent = 13.1%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,478] [INFO] [stage3.py:126:__init__] Reduce bucket size 16777216\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,478] [INFO] [stage3.py:127:__init__] Prefetch bucket size 15099494\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,595] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,596] [INFO] [utils.py:804:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,596] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 48.8 GB, percent = 13.1%\u001b[0m\n",
      "\u001b[34mParameter Offload: Total persistent parameters: 266240 in 65 params\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,941] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,942] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.99 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:17,942] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 49.3 GB, percent = 13.2%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:18,062] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:18,063] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:18,063] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 49.3 GB, percent = 13.2%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:20,752] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:20,753] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:20,754] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 58.87 GB, percent = 15.8%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:21,020] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:21,021] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:21,022] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 66.18 GB, percent = 17.7%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,404] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,405] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,405] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 81.56 GB, percent = 21.8%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,592] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,594] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:22,594] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 87.59 GB, percent = 23.4%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:27,524] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:27,524] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:27,524] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 162.66 GB, percent = 43.5%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:27,525] [INFO] [stage3.py:448:_setup_for_real_optimizer] optimizer state initialized\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,059] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [utils.py:804:see_memory_usage] MA 0.53 GB         Max_MA 1.02 GB         CA 1.31 GB         Max_CA 1 GB\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 176.27 GB, percent = 47.2%\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f60a9f35f90>\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,060] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[6e-06], mom=[[0.9, 0.999]]\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,061] [INFO] [config.py:967:print] DeepSpeedEngine configuration:\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,061] [INFO] [config.py:971:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,061] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,061] [INFO] [config.py:971:print]   amp_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,061] [INFO] [config.py:971:print]   amp_params ................... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   bfloat16_enabled ............. True\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f60a81dff70>\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   communication_data_type ...... None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   dataloader_drop_last ......... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   disable_allgather ............ False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   dump_state ................... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   elasticity_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   fp16_auto_cast ............... None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   fp16_enabled ................. False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   global_rank .................. 0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   grad_accum_dtype ............. None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 2\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,062] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 1\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   load_universal_checkpoint .... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   loss_scale ................... 1.0\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   memory_breakdown ............. False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   mics_shard_size .............. -1\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   optimizer_name ............... adamw\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   optimizer_params ............. {'lr': 6e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.2}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   pld_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   pld_params ................... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   prescale_gradients ........... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   scheduler_name ............... WarmupLR\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 6e-06, 'warmup_num_steps': 82}\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   sparse_attention ............. None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   steps_per_print .............. inf\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   train_batch_size ............. 16\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  2\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   use_node_local_storage ....... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   weight_quantization_config ... None\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   world_size ................... 4\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   zero_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,063] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3\u001b[0m\n",
      "\u001b[34m[2024-03-28 23:33:31,064] [INFO] [config.py:957:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 6e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.2\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 6e-06, \n",
      "            \"warmup_num_steps\": 82\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 1.677722e+07, \n",
      "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"gather_16bit_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"wall_clock_breakdown\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1812] 2024-03-28 23:33:31,064 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1813] 2024-03-28 23:33:31,064 >>   Num examples = 6,563\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1814] 2024-03-28 23:33:31,064 >>   Num Epochs = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1815] 2024-03-28 23:33:31,064 >>   Instantaneous batch size per device = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1818] 2024-03-28 23:33:31,064 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1819] 2024-03-28 23:33:31,064 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1820] 2024-03-28 23:33:31,064 >>   Total optimization steps = 820\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1812] 2024-03-28 23:33:31,064 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1813] 2024-03-28 23:33:31,064 >>   Num examples = 6,563\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1814] 2024-03-28 23:33:31,064 >>   Num Epochs = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1815] 2024-03-28 23:33:31,064 >>   Instantaneous batch size per device = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1818] 2024-03-28 23:33:31,064 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1819] 2024-03-28 23:33:31,064 >>   Gradient Accumulation steps = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1820] 2024-03-28 23:33:31,064 >>   Total optimization steps = 820\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1821] 2024-03-28 23:33:31,065 >>   Number of trainable parameters = 7,241,764,864\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1821] 2024-03-28 23:33:31,065 >>   Number of trainable parameters = 7,241,764,864\u001b[0m\n",
      "\u001b[34m0%|          | 0/820 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1/820 [00:37<8:32:24, 37.54s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/820 [01:09<7:48:51, 34.39s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/820 [01:41<7:29:13, 32.99s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/820 [02:11<7:14:57, 31.98s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/820 [02:42<7:09:15, 31.60s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/820 [03:13<7:07:05, 31.48s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/820 [03:44<7:05:34, 31.41s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/820 [04:15<7:03:00, 31.26s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9605, 'grad_norm': 16.8551677442706, 'learning_rate': 2.831278452291844e-06, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 8/820 [04:15<7:03:00, 31.26s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 9/820 [04:47<7:04:55, 31.44s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 10/820 [05:19<7:04:47, 31.47s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 11/820 [05:50<7:05:12, 31.54s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 12/820 [06:22<7:06:39, 31.68s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/820 [06:54<7:03:55, 31.52s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/820 [07:25<7:03:21, 31.52s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/820 [07:57<7:03:36, 31.57s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/820 [08:27<6:58:35, 31.24s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1455, 'grad_norm': 3.2164142615028806, 'learning_rate': 3.7750379363891255e-06, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/820 [08:27<6:58:35, 31.24s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/820 [08:59<7:01:35, 31.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 18/820 [09:31<7:02:59, 31.64s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 19/820 [10:03<7:01:45, 31.59s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/820 [10:34<6:58:22, 31.38s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-28 23:44:05,259 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-28 23:44:05,259 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-28 23:44:05,259 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-28 23:44:05,259 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-28 23:44:05,260 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-28 23:44:05,260 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:20,  1.61s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:51,  2.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:09<02:08,  2.68s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:17,  2.92s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:19,  3.04s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:29<02:18,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:12,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:39<02:08,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:02,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:49<01:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:56,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [00:59<01:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:09<01:40,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:22<01:26,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:22,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:32<01:16,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:13,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:42<01:06,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:52<00:56,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:52,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:02<00:46,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:15<00:33,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:29,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:22<00:26,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:25<00:23,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:20,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:35<00:13,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 49/52 [02:39<00:09,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 50/52 [02:42<00:06,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 51/52 [02:45<00:03,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1430799961090088, 'eval_runtime': 172.9313, 'eval_samples_per_second': 9.489, 'eval_steps_per_second': 0.301, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/820 [13:27<6:58:22, 31.38s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/820 [13:58<18:30:16, 83.37s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/820 [14:31<15:05:11, 68.06s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/820 [15:03<12:41:21, 57.32s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 24/820 [15:36<11:03:31, 50.01s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1422, 'grad_norm': 4.394555012956586, 'learning_rate': 4.3271018442859795e-06, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m3%|▎         | 24/820 [15:36<11:03:31, 50.01s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 25/820 [16:07<9:49:10, 44.47s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 26/820 [16:39<8:57:54, 40.65s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 27/820 [17:10<8:18:55, 37.75s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 28/820 [17:42<7:54:17, 35.93s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 29/820 [18:13<7:34:51, 34.50s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 30/820 [18:45<7:24:04, 33.73s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 31/820 [19:17<7:15:10, 33.09s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 32/820 [19:48<7:07:42, 32.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1388, 'grad_norm': 110.30675064968418, 'learning_rate': 4.718797420486407e-06, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m4%|▍         | 32/820 [19:48<7:07:42, 32.57s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 33/820 [20:19<7:02:36, 32.22s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 34/820 [20:50<6:58:01, 31.91s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 35/820 [21:22<6:58:01, 31.95s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 36/820 [21:54<6:54:35, 31.73s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 37/820 [22:26<6:54:20, 31.75s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 38/820 [22:57<6:52:49, 31.68s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 39/820 [23:29<6:52:56, 31.72s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 40/820 [24:01<6:52:09, 31.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1212, 'grad_norm': 3.287607373997037, 'learning_rate': 5.022620113233725e-06, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m5%|▍         | 40/820 [24:01<6:52:09, 31.70s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-28 23:57:32,091 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-28 23:57:32,091 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-28 23:57:32,091 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-28 23:57:32,091 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-28 23:57:32,091 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-28 23:57:32,091 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:26,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:56,  2.37s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:10,  2.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:20,  3.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:21,  3.14s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:12,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:40<02:08,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:50<01:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:57,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [01:00<01:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:10<01:40,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:26,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:23,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:33<01:16,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:12,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:43<01:06,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:53<00:56,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:52,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:03<00:46,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:16<00:32,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:29,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:22<00:26,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:26<00:23,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:19,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:36<00:13,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 49/52 [02:39<00:09,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 50/52 [02:42<00:06,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 51/52 [02:46<00:03,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11849519610404968, 'eval_runtime': 172.6419, 'eval_samples_per_second': 9.505, 'eval_steps_per_second': 0.301, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m5%|▍         | 40/820 [26:53<6:52:09, 31.70s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m5%|▌         | 41/820 [27:25<18:03:38, 83.46s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 42/820 [27:57<14:41:15, 67.96s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 43/820 [28:28<12:17:15, 56.93s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 44/820 [28:58<10:34:48, 49.08s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 45/820 [29:30<9:26:15, 43.84s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 46/820 [30:01<8:34:34, 39.89s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 47/820 [30:32<8:02:09, 37.42s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 48/820 [31:04<7:39:11, 35.69s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1199, 'grad_norm': 3.030383035224993, 'learning_rate': 5.270861328383261e-06, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m6%|▌         | 48/820 [31:04<7:39:11, 35.69s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 49/820 [31:35<7:18:53, 34.15s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 50/820 [32:06<7:07:58, 33.35s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 51/820 [32:37<6:59:18, 32.72s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 52/820 [33:09<6:53:40, 32.32s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 53/820 [33:40<6:49:41, 32.05s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 54/820 [34:12<6:49:33, 32.08s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 55/820 [34:44<6:49:03, 32.08s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 56/820 [35:16<6:47:47, 32.02s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1204, 'grad_norm': 2.1603251661925094, 'learning_rate': 5.4807462852108925e-06, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m7%|▋         | 56/820 [35:16<6:47:47, 32.02s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 57/820 [35:48<6:44:40, 31.82s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 58/820 [36:19<6:42:51, 31.72s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 59/820 [36:51<6:41:25, 31.65s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 60/820 [37:22<6:40:27, 31.61s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 00:10:53,735 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 00:10:53,735 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 00:10:53,736 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 00:10:53,736 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 00:10:53,737 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 00:10:53,737 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:25,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:55,  2.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:11,  2.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:21,  3.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:19,  3.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.27s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|█         | 85/820 [56:13<9:02:44, 44.31s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 139/820 [1:30:11<5:51:25, 30.96s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 140/820 [1:30:42<5:50:47, 30.95s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:04:13,151 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:04:13,151 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:04:13,152 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:04:13,152 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:04:13,153 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:04:13,153 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:25,  1.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:55,  2.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:09<02:10,  2.71s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:20,  3.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m20%|█▉        | 163/820 [1:48:27<10:21:11, 56.73s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 164/820 [1:48:57<8:53:42, 48.81s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 165/820 [1:49:28<7:55:12, 43.53s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 166/820 [1:50:00<7:15:33, 39.96s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 167/820 [1:50:32<6:48:09, 37.50s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 168/820 [1:51:03<6:26:04, 35.53s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1067, 'grad_norm': 1.6634572679117967, 'learning_rate': 6e-06, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m20%|██        | 168/820 [1:51:03<6:26:04, 35.53s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 169/820 [1:51:35<6:14:33, 34.52s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 170/820 [1:52:07<6:04:43, 33.67s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 171/820 [1:52:38<5:56:14, 32.93s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 172/820 [1:53:09<5:51:31, 32.55s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 173/820 [1:53:41<5:47:00, 32.18s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 174/820 [1:54:12<5:41:52, 31.75s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 175/820 [1:54:44<5:42:10, 31.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 176/820 [1:55:15<5:39:51, 31.66s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1129, 'grad_norm': 2.3280102234268525, 'learning_rate': 6e-06, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m21%|██▏       | 176/820 [1:55:15<5:39:51, 31.66s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 177/820 [1:55:46<5:37:59, 31.54s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 178/820 [1:56:18<5:37:50, 31.57s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 179/820 [1:56:49<5:37:14, 31.57s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 180/820 [1:57:21<5:37:01, 31.60s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:30:52,529 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:30:52,529 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:30:52,531 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:30:52,531 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:30:52,532 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:30:52,532 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:26,  1.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:56,  2.38s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:11,  2.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.95s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:21,  3.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:20<02:21,  3.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:12,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:40<02:08,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:50<02:00,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:57,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [01:00<01:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:10<01:40,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:26,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:22,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:33<01:16,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:12,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:43<01:06,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:53<00:56,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:53,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:03<00:46,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 206/820 [2:16:47<6:51:56, 40.25s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 207/820 [2:17:18<6:21:34, 37.35s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 208/820 [2:17:48<5:58:50, 35.18s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1236, 'grad_norm': 1.558383401620581, 'learning_rate': 6e-06, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 208/820 [2:17:48<5:58:50, 35.18s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 209/820 [2:18:18<5:43:01, 33.69s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 210/820 [2:18:48<5:31:34, 32.61s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 211/820 [2:19:19<5:26:36, 32.18s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 212/820 [2:19:51<5:23:54, 31.97s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 213/820 [2:20:22<5:20:49, 31.71s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 214/820 [2:20:53<5:19:43, 31.66s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 215/820 [2:21:25<5:18:45, 31.61s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 216/820 [2:21:56<5:18:08, 31.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1203, 'grad_norm': 2.3542442618441197, 'learning_rate': 6e-06, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m26%|██▋       | 216/820 [2:21:56<5:18:08, 31.60s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 217/820 [2:22:27<5:15:42, 31.41s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 218/820 [2:22:59<5:14:37, 31.36s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 219/820 [2:23:30<5:13:36, 31.31s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 220/820 [2:24:01<5:11:24, 31.14s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:57:32,121 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 01:57:32,121 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:57:32,121 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:57:32,121 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 01:57:32,121 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 01:57:32,121 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:25,  1.70s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:55,  2.35s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:10,  2.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:20,  3.06s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.12s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.18s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:12,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:39<02:08,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:49<01:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:56,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [00:59<01:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:09<01:40,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:26,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:23,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:33<01:16,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:13,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:43<01:06,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:53<00:56,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:53,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:02<00:46,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:16<00:33,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:29,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:22<00:26,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:26<00:23,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:20,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:36<00:13,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 49/52 [02:39<00:09,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 50/52 [02:42<00:06,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 51/52 [02:46<00:03,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11268267035484314, 'eval_runtime': 172.7244, 'eval_samples_per_second': 9.501, 'eval_steps_per_second': 0.301, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 220/820 [2:26:53<5:11:24, 31.14s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 52/52 [02:49<00:00,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 221/820 [2:27:24<13:48:10, 82.96s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 222/820 [2:27:56<11:12:54, 67.52s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 223/820 [2:28:28<9:25:22, 56.82s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 224/820 [2:28:59<8:09:20, 49.26s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1164, 'grad_norm': 1.8133962980142353, 'learning_rate': 6e-06, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 224/820 [2:28:59<8:09:20, 49.26s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 225/820 [2:29:32<7:18:02, 44.17s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 226/820 [2:30:02<6:37:25, 40.14s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 227/820 [2:30:34<6:11:35, 37.60s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 228/820 [2:31:05<5:52:07, 35.69s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 229/820 [2:31:36<5:35:46, 34.09s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 230/820 [2:32:07<5:27:08, 33.27s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 231/820 [2:32:39<5:21:30, 32.75s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 253/820 [2:46:58<5:01:55, 31.95s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 538/820 [5:57:26<2:29:58, 31.91s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 539/820 [5:57:57<2:28:35, 31.73s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 540/820 [5:58:29<2:27:45, 31.66s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:32:00,539 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:32:00,539 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:32:00,542 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:32:00,542 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:32:00,542 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:32:00,542 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:24,  1.69s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:55,  2.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:11,  2.74s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.94s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:21,  3.07s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:21,  3.14s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.20s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:11,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:39<02:07,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:04,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:01,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:49<01:59,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:56,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [00:59<01:49,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:09<01:39,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:26,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:22,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:32<01:16,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:12,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:42<01:06,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:52<00:56,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:53,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:02<00:46,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:16<00:33,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:30,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:22<00:26,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:26<00:23,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:19,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:35<00:13,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 49/52 [02:39<00:10,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 50/52 [02:42<00:06,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 51/52 [02:45<00:03,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11631432920694351, 'eval_runtime': 172.6312, 'eval_samples_per_second': 9.506, 'eval_steps_per_second': 0.301, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 540/820 [6:01:22<2:27:45, 31.66s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 541/820 [6:01:54<6:28:58, 83.65s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 542/820 [6:02:26<5:15:37, 68.12s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 543/820 [6:02:57<4:23:08, 57.00s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 544/820 [6:03:28<3:46:11, 49.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0716, 'grad_norm': 1.3919426750925175, 'learning_rate': 6e-06, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 544/820 [6:03:28<3:46:11, 49.17s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 545/820 [6:03:59<3:20:10, 43.68s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 546/820 [6:04:30<3:02:10, 39.89s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 547/820 [6:05:01<2:49:54, 37.34s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 548/820 [6:05:33<2:41:27, 35.62s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 549/820 [6:06:04<2:35:07, 34.35s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 550/820 [6:06:35<2:29:46, 33.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 551/820 [6:07:07<2:27:16, 32.85s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 552/820 [6:07:38<2:24:37, 32.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0702, 'grad_norm': 1.5512408481115836, 'learning_rate': 6e-06, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 552/820 [6:07:38<2:24:37, 32.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 553/820 [6:08:10<2:23:14, 32.19s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 554/820 [6:08:41<2:21:46, 31.98s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 555/820 [6:09:12<2:20:03, 31.71s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 556/820 [6:09:44<2:19:22, 31.67s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 557/820 [6:10:15<2:18:30, 31.60s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 558/820 [6:10:47<2:18:20, 31.68s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 559/820 [6:11:18<2:17:16, 31.56s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 560/820 [6:11:50<2:16:12, 31.43s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0645, 'grad_norm': 1.1937427810131112, 'learning_rate': 6e-06, 'epoch': 1.36}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 560/820 [6:11:50<2:16:12, 31.43s/it]\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:45:21,159 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:45:21,159 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:45:21,159 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:45:21,159 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:45:21,159 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:45:21,159 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:26,  1.72s/it]#033[A\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:55,  2.36s/it]#033[A\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:10,  2.73s/it]#033[A\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:17,  2.93s/it]#033[A\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:20,  3.05s/it]#033[A\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.13s/it]#033[A\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.19s/it]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.26s/it]#033[A\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:14,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:11,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:39<02:08,  3.28s/it]#033[A\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:01,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:49<01:59,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:56,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [00:59<01:49,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:09<01:40,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:36,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:28,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:25,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:22,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:19,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:32<01:16,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:13,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:42<01:06,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<00:59,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:52<00:56,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:52,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:02<00:46,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.30s/it]#033[A\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.29s/it]#033[A\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:12<00:36,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:15<00:33,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:29,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:22<00:26,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:25<00:23,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:20,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.33s/it]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:35<00:13,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 49/52 [02:39<00:10,  3.34s/it]#033[A\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 50/52 [02:42<00:06,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 51/52 [02:45<00:03,  3.32s/it]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11602617800235748, 'eval_runtime': 172.5025, 'eval_samples_per_second': 9.513, 'eval_steps_per_second': 0.301, 'epoch': 1.36}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 560/820 [6:14:42<2:16:12, 31.43s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 52/52 [02:49<00:00,  3.31s/it]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2067] 2024-03-29 05:48:13,663 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2067] 2024-03-29 05:48:13,663 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2271] 2024-03-29 05:48:13,663 >> Loading best model from /opt/ml/model/checkpoint-500 (score: 0.11437919735908508).\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2271] 2024-03-29 05:48:13,663 >> Loading best model from /opt/ml/model/checkpoint-500 (score: 0.11437919735908508).\u001b[0m\n",
      "\u001b[34m[INFO|deepspeed.py:427] 2024-03-29 05:48:13,664 >> Attempting to resume from /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34m[INFO|deepspeed.py:427] 2024-03-29 05:48:13,664 >> Attempting to resume from /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:13,674] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /opt/ml/model/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:13,681] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /opt/ml/model/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:13,681] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /opt/ml/model/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:13,689] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /opt/ml/model/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:13,697] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /opt/ml/model/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:22,538] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /opt/ml/model/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:22,538] [INFO] [engine.py:2932:_get_all_zero_checkpoint_state_dicts] successfully read 4 ZeRO state_dicts for rank 0\u001b[0m\n",
      "\u001b[34m[2024-03-29 05:48:28,692] [INFO] [engine.py:2882:_load_zero_checkpoint] loading 4 zero partition checkpoints for rank 0\u001b[0m\n",
      "\u001b[34m{'train_runtime': 22499.1555, 'train_samples_per_second': 0.583, 'train_steps_per_second': 0.036, 'train_loss': 0.11411636285483837, 'epoch': 1.36}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 560/820 [6:14:59<2:16:12, 31.43s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 560/820 [6:14:59<2:54:06, 40.18s/it]\u001b[0m\n",
      "\u001b[34m***** train metrics *****\u001b[0m\n",
      "\u001b[34mepoch                    =       1.36\n",
      "  train_loss               =     0.1141\n",
      "  train_runtime            = 6:14:59.15\n",
      "  train_samples            =       6563\n",
      "  train_samples_per_second =      0.583\n",
      "  train_steps_per_second   =      0.036\u001b[0m\n",
      "\u001b[34m03/29/2024 05:48:30 - INFO - jumpstart -   Start Evaluation.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:48:30,229 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3376] 2024-03-29 05:48:30,229 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:48:30,229 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:48:30,229 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3378] 2024-03-29 05:48:30,229 >>   Num examples = 1641\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:3381] 2024-03-29 05:48:30,229 >>   Batch size = 8\u001b[0m\n",
      "\u001b[34m0%|          | 0/52 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 2/52 [00:03<01:25,  1.72s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 3/52 [00:06<01:56,  2.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 4/52 [00:10<02:11,  2.74s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 5/52 [00:13<02:18,  2.95s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 6/52 [00:16<02:20,  3.06s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 7/52 [00:19<02:20,  3.13s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 8/52 [00:23<02:20,  3.20s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 9/52 [00:26<02:20,  3.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 10/52 [00:30<02:18,  3.31s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 11/52 [00:33<02:15,  3.30s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 12/52 [00:36<02:12,  3.31s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 13/52 [00:40<02:08,  3.30s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 14/52 [00:43<02:05,  3.30s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 15/52 [00:46<02:02,  3.32s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 16/52 [00:50<02:00,  3.33s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 17/52 [00:53<01:56,  3.33s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 18/52 [00:56<01:52,  3.32s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 19/52 [00:59<01:49,  3.32s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 20/52 [01:03<01:46,  3.32s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 21/52 [01:06<01:43,  3.34s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 22/52 [01:09<01:39,  3.32s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 23/52 [01:13<01:35,  3.31s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 24/52 [01:16<01:32,  3.30s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 25/52 [01:19<01:29,  3.30s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 26/52 [01:23<01:26,  3.32s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 27/52 [01:26<01:23,  3.33s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 28/52 [01:29<01:20,  3.34s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 29/52 [01:33<01:16,  3.34s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 30/52 [01:36<01:13,  3.33s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 31/52 [01:39<01:09,  3.32s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 32/52 [01:43<01:06,  3.31s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 33/52 [01:46<01:02,  3.31s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 34/52 [01:49<01:00,  3.34s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 35/52 [01:53<00:56,  3.33s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 36/52 [01:56<00:53,  3.32s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 37/52 [01:59<00:49,  3.32s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 38/52 [02:03<00:46,  3.32s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 39/52 [02:06<00:42,  3.31s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 40/52 [02:09<00:39,  3.31s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 41/52 [02:13<00:36,  3.33s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 42/52 [02:16<00:33,  3.32s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 43/52 [02:19<00:29,  3.32s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 44/52 [02:23<00:26,  3.31s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 45/52 [02:26<00:23,  3.32s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 46/52 [02:29<00:19,  3.32s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 47/52 [02:32<00:16,  3.32s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 48/52 [02:36<00:13,  3.31s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "instruction_tuned_estimator = JumpStartEstimator(\n",
    "    model_id=model_id,\n",
    "    hyperparameters=my_hyperparameters,\n",
    "    output_path=f\"s3://{bucket_name}/model/email-type/{model}/{timestamp}\",\n",
    "    instance_type=\"ml.g5.24xlarge\",\n",
    ")\n",
    "instruction_tuned_estimator.fit({\"train\": train_data_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f5e74-50aa-4443-8065-e18fe5ff6400",
   "metadata": {},
   "source": [
    "##### Extract Training performance metrics. Performance metrics such as training loss and validation accuracy/loss can be accessed through cloudwatch while the training. We can also fetch these metrics and analyze them within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfc1af-c128-42c3-9b7e-fe8c883d5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = instruction_tuned_estimator.latest_training_job.job_name\n",
    "\n",
    "df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc1ffaa-78f1-43df-8884-27b6b733e490",
   "metadata": {},
   "source": [
    "### 1.4. Deploying inference endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8413049-8114-4203-aad2-11a423725b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_tuned_predictor = instruction_tuned_estimator.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bceeea8-1399-4bc8-84fd-7898789b7a4b",
   "metadata": {},
   "source": [
    "### 1.5. Clean up the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27e2a2-b92f-480f-a7fd-4e614d378bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "instruction_tuned_predictor.delete_model()\n",
    "instruction_tuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e217459-d97f-44ab-bb30-8892d274427a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
